:encoding: iso-8859-1

= Testdokumentation

Die folgenden Seiten befassen sich mit dem Testen des Systems. Ziel ist es die Qualitaet des Systems nachzuweisen, sowie die Teststrukturen zu dokumentieren. 

== Inhaltsverzeichnis
. *Testkonzept*
.. Die wichtigsten Systemkomponenten (Testobjekte)
.. Vorgehensweise (Testmethoden) / Testdurchfuehrungsplan
. *Testfaelle*
.. automatisierte UnitTests (BackEnd)
.. manuelle Testfaelle (FrontEnd)
. *Testergebnisse*

== 1 Testkonzept
'Teststrategie'

In diesem Punkt wird analysiert, in welchen Systemkomponenten das Testen am wichtigsten ist. Diese Komponenten werden spaeter fuer die entstehenden Tests priorisiert betrachtet.
Da es fuer uns nicht Moeglich war, eine 100 prozentige Testabdeckung zu gewaehrleisten, haben wir uns fuer dieses Vorgehen entschieden. Um einen Ueberblick ueber die Testfaelle zu bekommen, wurde eng mit dem Entwicklerteam zusammengearbeitet.
Es wurde das komplette System durchleuchtet und die Kernfunktionen bestimmt. Diese Kernfunktionen sollen durch die Tests abgedeckt werden koennen, um ein fehlerfreies Laufen des Systems sicherzustellen.
Entstandene Testfaellen wurden in einer Liste festgehalten. Diese Testfaelle beschreiben:

* Einzuhaltende Vorbedingung
* Eingabedaten
* Erwartetes Ergebnis

Zudem wurden sie noch einmal zusaetzlich in manuelle- und automatische Tests unterteilt. Der Anwendungsbereich fuer die automatisierten Testfaelle liegt ausschliesslich im BackEnd und die manuellen Testfaelle im FrontEnd.





*a) Testobjekte*
  
.Testfaelle BackEnd
[width="80%",cols="3,^2,^2,10",options="header"]
|=========================================================
|Testfall |Vorbedingung |Eingabedaten |Ergebnis

|Django Schnittstelle |Der Server muss laufen | JSON-File mit den (Wetter)daten |
Die Daten aus der JSON-File werden korrekt in die versch. Tabellen aufgeteilt. Jede Tabelle wurde mit neuen Werten erweitert.

|QueryByime-Funktion |Der Server muss laufen & die Tabellen muessen leer sein | Drei Eintrage mit versch. Daten  |
Es werden immer nur die Eintraege erkannt, die in dem gewaehlten Zeitraum liegen.

|Mapping der Sensordaten |Server muss laufen |JSON-File mit den (Wetter)daten |
Die Kuerzel 'deg' & 'dir' werden zu den Begriffen 'degrees' & 'direction' und das Wort 'timestamp' wird zu 'measure time' 

|Rasberry Pi Skript|x |x |
x

|Login Funktion|x | x |
x

|=========================================================


*b) Testmethoden*

'Testumgebung'

Die Testumgebung beschreibt, welche Werkzeuge fuer das Testen eingesetzt werden. Es wurde hauptsaechlich mit UnitTests in Python gearbeiten. Dazu kamen noch weitere Integrationstests um das genutzte Django-Framework zu testen.
Damit wurden alle Sachen aus dem Backend abgedeckt. Das FrontEnd wurde mit sogennanten User-Acceptance-Tests(End-User-Tests) bearbeitet. Um dies sinnvoll zu gestalten wurde eine Liste mit versch. Testfaellen erstellt um die Konsistenz zu sichern.
Bei der Uebergabe gab es noch Abnahmetests zusammen mit dem Kunden (Ergebnisse im Punkt 'Testergebnisse'). Dazu wurden auch die Testfaelle aus den FrontEndTests genutzt.

'Testorganisation'

Wann und Wie wird getestet? Wir haben ein Concurrent Testing angestrebt, dass bedeutet es wurden die Tests simultan zur Codeerweiterung entwickelt. Damit sollte gewaehrleistet werden, dass immer der groesstmoeglichste Teil des Systems durch Tests
abgedeckt ist. Ausserdem soll dies auch ein Verzug der Tests verhindern. 

== 2 Testfaelle

*a) Automatisierte UnitTests*

Im ersten Testfall wird eine JSON-File an unsere Django-Schnittstelle gesendet. Diese ist dafuer da, die enthaltenden Daten auf die einzelnen Tabellen aufzuteilen. Um zu kontrollieren ob es tatsaechlich funktioniert hat, wird mit Hilfe von
einzelnen 'assertEqual'-Abfragen geschaut, ob die Werte in den Tabellen gelangt sind. Moeglichkeiten waeren z.B. das Abfragen der Anzahl von Eintraegen in einer Tabelle, oder sogar nach bestimmten Werten in der Tabelle. Ausserdem wird der 
Statuscode abgefragt (HTTP_201_CREATED). Wenn dieser korrekt ist gibt das System eine Meldung aus.  

.Test des Django-Framework
image::DJANGO.jpg[]

Die QueryByTime-Funktion wird dadruch getestet, dass wir zuerst drei versch. Eintraege posten. Danach schauen wir ob diese drei Eintraege erfolgreich erstellt wurden, indem wir die Anzahl mit der Zahl '3' vergleichen. Wenn dies erfolgreich
war, setzten wir nun ein festen Start- & Endpunkt fest. Nun folgen wieder assertEqual-Abfragen wo wir gezielt nur nach einzelen Eintraegen suchen. 

.Test der Datumsabfrage
image::QUERYBYTIME.jpg[]  

Der dritte Testfall kontrolliert, ob die in der JSON-File enthaltenen Kuerzel ordentlich gemapped werden. Bei den drei assert-Abfragen ist das Vorgehen immer das gleiche. Mit dem Befehl 'assertIsNotNone' wird geschaut, dass das erwuenschte Wort
vorhanden ist. Falls nicht kommt eine Fehlermeldung, die den Nutzer darauf hinweist. 

.Test zum Mapping
image::MAPPING.jpg[]

*b) manuelle Tests*

Hierfuer wurde eine Liste erstellt, die zum testen des FrontEnds genutzt wurde. Sie soll alle Moeglichkeiten abdecken und die Resultate dokumentieren. Sie wird auch gleichzeitig fuer den Abnahmetest am Ende verwendet.


.Testfaelle FrontEnd
[width="80%",cols="3,1",options="header"]
|=========================================================
|Testfall | Ergebnis

| Beim klicken auf das "Wetterstation-Logo" gelangt man auf die Startseite | ja [ ] nein [ ]

| Graphen werden beim Aufruf der Startseite mit den Standardeinstellungen erstellt ( 1 Tag bei den Temperaturdaten / 4h bei den Winddaten ) und dargestellt | ja [ ] nein [ ]

| Die angezeigten Daten sind (logisch) korrekt | ja [ ] nein [ ]

| vorgefertigte Zeitraume (Auswahlfelder) lassen sich auswaehlen und aktualisieren den Graphen | ja [ ] nein [ ]

| Detaillierte Ansicht der einzelenen Datenpunkte ist mit dem Cursor moeglich | ja [ ] nein [ ]

|Erweiterter Modus funktioniert (selbststaendig einen Zeitraum bestimmen) | ja [ ] nein [ ]

|Wenn der angegebene Zeitraum logisch falsch ist, wird der Graph NICHT aktualisiert | ja [ ] nein [ ]

|Tab "Webcam&Galerie": Weiterleitung in die Galerie. das aktuellste Bild wird gross dargestellt und die aelteren Bilder sind nach Datum in Reitern geordnet | ja [ ] nein [ ]

|Bei der Auswahl eines Bildes oeffnet sich eine "LightBox" | ja [ ] nein [ ]

|Login mit korrektem Benutzernamen/Passwort leitet zum Wartungsbereich weiter | ja [ ] nein [ ]

|Bei falschem Benutzernamen/Passwort wird die Login-Seite neu geladen | ja [ ] nein [ ]

|Die Zu-/Abwahl von Graphen ist durch Auswahlfelder moeglich (Wartungsbereich), der Graph wird aktualisiert | ja [ ] nein [ ]

|Die Achsenbeschriftung aendert sich mit der Auswahl der dargestellten Daten Wartungsbereich) | ja [ ] nein [ ] 
|=========================================================

== 3 Testergebnisse

Die Ergebnisse der Test waren eigentlich immer erfolgreich. Sie entstanden trotz Concurrent Testing mit leichter Verzoegerung und dienten dadurch eher zur Sicherung des Systems. Nach System-
updates konnte man die Tests durchlaufen lassen und schauen, ob die bereits bestehenden Komponenten trotzdem noch funktionierten. Da unser Entwicklerteam durchgehend gute Arbeit geleistet
hatte und sowohl bei der Entwicklung des Systems, als auch beim Support der Testentwicklung stets behilflich war, haben die Tests durchgehend die positive Entwicklung des Systems bestaetigt.
Deshalb kam es zu keinen signifikaten Abweichungen, auf die man haette eingehen muessen. Die vermeintlichen Probleme sind durch die gute Zusammenarbeit zwischen dem Team und der Auftraggeber schon bereits
frueh erkannt worden und konnten somit schon bei der Implementierung vermieden/geloest werden.   

*Abnahmetestergebnis*




